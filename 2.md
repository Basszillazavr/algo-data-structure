### **Lecture: Data Structures and Space Complexity** ðŸ§ 

#### **1. What is Space Complexity?**

**Space complexity** is a measure of the amount of working memory (or temporary storage) an algorithm needs to run to completion. Itâ€™s the total space used by the algorithm, including both the space for input values and any **auxiliary space** (extra space used by the algorithm itself, like variables, arrays, or data structures created during execution).

For this lecture, we will focus on **auxiliary space complexity**, as it directly reflects the efficiency of the algorithm's memory usage, independent of the input size.

#### **2. Why Does Space Complexity Matter?**

* **Memory Constraints:** In environments with limited memory, like embedded systems, smartphones, or older computers, an algorithm with high space complexity can cause the program to crash due to "out of memory" errors.
* **Performance:** Accessing memory can be a time-consuming operation. Algorithms that use less memory can sometimes be faster due to better cache utilization.
* **Scalability:** A low-space complexity algorithm is more scalable. It can handle larger inputs without requiring a corresponding massive increase in memory.

#### **3. Big O Notation for Space Complexity**

Just like with time complexity, we use **Big O notation** to describe the relationship between the input size ($n$) and the amount of memory an algorithm uses.

* $O(1)$ **Constant Space**: The amount of memory used is the same regardless of the input size. For example, an algorithm that only uses a few variables to store counts or temporary values.
* $O(n)$ **Linear Space**: The memory used grows in direct proportion to the input size. For example, if you create a new array to hold a copy of all the elements from the input array.
* $O(n^2)$ **Quadratic Space**: The memory used grows as the square of the input size. This often occurs when you use a two-dimensional array or a nested data structure where both dimensions depend on the input size.
* $O(\\log n)$ **Logarithmic Space**: The memory used grows very slowly as the input size increases. This is common in recursive algorithms where the call stack's depth is logarithmic, such as in binary search.

-----

### **4. How Data Structures Impact Space Complexity**

The data structures you choose directly influence an algorithm's space complexity.

* **Arrays**:

    * **Space**: An array of size $n$ requires $O(n)$ space.
    * **Example**: Creating a new array to store sorted elements from another array will have an auxiliary space complexity of $O(n)$.

* **Linked Lists**:

    * **Space**: A linked list with $n$ nodes also requires $O(n)$ space because each node takes up a fixed amount of memory.
    * **Example**: An algorithm that duplicates a linked list to reverse it will have $O(n)$ space complexity.

* **Stacks and Queues**:

    * **Space**: If implemented with a dynamic array, they can grow up to $O(n)$ in the worst case.
    * **Example**: An algorithm that uses a stack to reverse a string of length $n$ will have $O(n)$ space complexity because the stack will store all $n$ characters.

* **Hash Maps (Dictionaries)**:

    * **Space**: The space depends on the number of key-value pairs. Storing $n$ items would be $O(n)$.
    * **Example**: An algorithm that counts the frequency of each element in an array of size $n$ using a hash map will have a space complexity of $O(k)$, where $k$ is the number of unique elements. In the worst case, $k$ could be $n$, making the space complexity $O(n)$.

-----

### **5. Practice & Discussion**

Let's analyze the space complexity of a few common algorithms.

**Problem 1: Sum of an Array**

```python
def sum_array(arr):
    total = 0
    for num in arr:
        total += num
    return total
```

* **Analysis**: This function uses a single variable `total`. The memory it uses is constant, regardless of the size of the input array.
* **Space Complexity**: $O(1)$

**Problem 2: Creating a Doubled List**

```python
def double_list(arr):
    new_list = []
    for num in arr:
        new_list.append(num * 2)
    return new_list
```

* **Analysis**: This function creates a `new_list` that grows to the same size as the input `arr`. If the input has $n$ elements, the `new_list` will also have $n$ elements.
* **Space Complexity**: $O(n)$

**Problem 3: Binary Search**

* **Iterative Version**: The iterative binary search algorithm only uses a few variables (`low`, `high`, `mid`).
* **Space Complexity**: $O(1)$
* **Recursive Version**: The recursive version creates a new function call on the call stack for each step. The depth of the recursion is logarithmic.
* **Space Complexity**: $O(\\log n)$


```python
# Create a list of fruits
fruits = ["apple", "banana", "apple", "orange", "banana", "apple"]

# Create an empty dictionary to act as our hash map
fruit_counts = {}

# Iterate through the list and count the frequency of each fruit
for fruit in fruits:
    # If the fruit is already in the dictionary, increment its count
    if fruit in fruit_counts:
        fruit_counts[fruit] += 1
    # If the fruit is not in the dictionary, add it with a count of 1
    else:
        fruit_counts[fruit] = 1

# Print the final hash map (dictionary)
print(fruit_counts)
```
